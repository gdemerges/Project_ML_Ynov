"""
MLflow Configuration Module
Projet: MindPulse - Student Depression Prediction

Ce module fournit les fonctions utilitaires pour l'int√©gration MLflow.
"""

import mlflow
import mlflow.sklearn
from mlflow.tracking import MlflowClient
import os
from pathlib import Path
from datetime import datetime

# Configuration MLflow
MLFLOW_TRACKING_URI = os.getenv("MLFLOW_TRACKING_URI", "http://localhost:5000")
EXPERIMENT_NAME = "student-depression-prediction"
MODEL_NAME = "depression-classifier"


def setup_mlflow():
    """Configure MLflow avec le tracking URI et l'exp√©rience"""
    mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)
    
    # Cr√©er ou r√©cup√©rer l'exp√©rience
    experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)
    if experiment is None:
        experiment_id = mlflow.create_experiment(
            EXPERIMENT_NAME,
            artifact_location=f"mlflow-artifacts/{EXPERIMENT_NAME}"
        )
        print(f"‚úÖ Exp√©rience '{EXPERIMENT_NAME}' cr√©√©e (ID: {experiment_id})")
    else:
        experiment_id = experiment.experiment_id
        print(f"üìä Exp√©rience '{EXPERIMENT_NAME}' existante (ID: {experiment_id})")
    
    mlflow.set_experiment(EXPERIMENT_NAME)
    return experiment_id


def log_model_training(
    model,
    model_name: str,
    metrics: dict,
    params: dict = None,
    artifacts: dict = None,
    tags: dict = None,
    input_example=None,
    signature=None
):
    """
    Log un entra√Ænement de mod√®le dans MLflow.
    
    Args:
        model: Le mod√®le entra√Æn√©
        model_name: Nom du mod√®le (ex: "Random Forest")
        metrics: Dict des m√©triques (accuracy, f1_score, etc.)
        params: Dict des hyperparam√®tres
        artifacts: Dict {nom: chemin} des artifacts √† logger
        tags: Dict des tags additionnels
        input_example: Exemple d'input pour la signature du mod√®le
        signature: Signature MLflow du mod√®le
    
    Returns:
        run_id: L'ID du run MLflow
    """
    with mlflow.start_run(run_name=f"{model_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}") as run:
        run_id = run.info.run_id
        
        # Log des tags
        mlflow.set_tag("model_type", model_name)
        mlflow.set_tag("project", "mindpulse")
        mlflow.set_tag("task", "binary_classification")
        if tags:
            for key, value in tags.items():
                mlflow.set_tag(key, value)
        
        # Log des param√®tres
        if params:
            mlflow.log_params(params)
        
        # Log des m√©triques
        for metric_name, metric_value in metrics.items():
            mlflow.log_metric(metric_name, metric_value)
        
        # Log du mod√®le sklearn
        mlflow.sklearn.log_model(
            model,
            artifact_path="model",
            input_example=input_example,
            signature=signature
        )
        
        # Log des artifacts suppl√©mentaires (fichiers pickle, etc.)
        if artifacts:
            for artifact_name, artifact_path in artifacts.items():
                if Path(artifact_path).exists():
                    mlflow.log_artifact(artifact_path, artifact_name)
        
        print(f"‚úÖ Run MLflow enregistr√©: {run_id}")
        print(f"   üìä M√©triques: {metrics}")
        
        return run_id


def compare_and_register_best_model(metrics: dict, model_name: str, run_id: str):
    """
    Compare les m√©triques avec le mod√®le en production et enregistre si meilleur.
    
    Args:
        metrics: Dict des m√©triques du nouveau mod√®le
        model_name: Nom du type de mod√®le
        run_id: ID du run MLflow
    
    Returns:
        registered: True si le mod√®le a √©t√© enregistr√© comme nouveau champion
    """
    client = MlflowClient()
    
    # V√©rifier si un mod√®le existe d√©j√† en production
    try:
        latest_versions = client.get_latest_versions(MODEL_NAME, stages=["Production"])
        
        if latest_versions:
            # R√©cup√©rer les m√©triques du mod√®le en production
            prod_run_id = latest_versions[0].run_id
            prod_run = client.get_run(prod_run_id)
            prod_accuracy = float(prod_run.data.metrics.get("accuracy", 0))
            
            new_accuracy = metrics.get("accuracy", 0)
            
            if new_accuracy > prod_accuracy:
                print(f"üéØ Nouveau mod√®le meilleur! ({new_accuracy:.4f} > {prod_accuracy:.4f})")
                _register_model_to_production(client, run_id)
                return True
            else:
                print(f"‚ÑπÔ∏è Mod√®le existant conserv√© ({prod_accuracy:.4f} >= {new_accuracy:.4f})")
                # Enregistrer quand m√™me dans le registry mais pas en production
                _register_model_staging(client, run_id)
                return False
        else:
            # Pas de mod√®le en production, enregistrer celui-ci
            print("üÜï Premier mod√®le, enregistrement en production")
            _register_model_to_production(client, run_id)
            return True
            
    except Exception as e:
        # Le mod√®le n'existe pas encore dans le registry
        print(f"üÜï Cr√©ation du mod√®le dans le registry: {MODEL_NAME}")
        _register_model_to_production(client, run_id)
        return True


def _register_model_to_production(client: MlflowClient, run_id: str):
    """Enregistre un mod√®le en production"""
    model_uri = f"runs:/{run_id}/model"
    
    # Enregistrer le mod√®le
    mv = mlflow.register_model(model_uri, MODEL_NAME)
    
    # Passer en production
    client.transition_model_version_stage(
        name=MODEL_NAME,
        version=mv.version,
        stage="Production",
        archive_existing_versions=True
    )
    
    print(f"‚úÖ Mod√®le enregistr√© en production (version {mv.version})")


def _register_model_staging(client: MlflowClient, run_id: str):
    """Enregistre un mod√®le en staging"""
    model_uri = f"runs:/{run_id}/model"
    
    mv = mlflow.register_model(model_uri, MODEL_NAME)
    
    client.transition_model_version_stage(
        name=MODEL_NAME,
        version=mv.version,
        stage="Staging"
    )
    
    print(f"üì¶ Mod√®le enregistr√© en staging (version {mv.version})")


def load_production_model():
    """Charge le mod√®le en production depuis MLflow"""
    model_uri = f"models:/{MODEL_NAME}/Production"
    
    try:
        model = mlflow.sklearn.load_model(model_uri)
        print(f"‚úÖ Mod√®le de production charg√©: {MODEL_NAME}")
        return model
    except Exception as e:
        print(f"‚ö†Ô∏è Impossible de charger le mod√®le de production: {e}")
        return None


def get_model_info():
    """R√©cup√®re les informations sur le mod√®le en production"""
    client = MlflowClient()
    
    try:
        versions = client.get_latest_versions(MODEL_NAME, stages=["Production"])
        
        if versions:
            version = versions[0]
            run = client.get_run(version.run_id)
            
            return {
                "model_name": MODEL_NAME,
                "version": version.version,
                "stage": version.current_stage,
                "run_id": version.run_id,
                "metrics": run.data.metrics,
                "params": run.data.params,
                "tags": run.data.tags,
                "created_at": version.creation_timestamp
            }
        return None
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur lors de la r√©cup√©ration des infos mod√®le: {e}")
        return None


def log_prediction_metrics(predictions_count: int, avg_confidence: float = None):
    """Log des m√©triques de pr√©diction pour le monitoring"""
    with mlflow.start_run(run_name=f"predictions_{datetime.now().strftime('%Y%m%d_%H%M%S')}"):
        mlflow.set_tag("type", "inference_metrics")
        mlflow.log_metric("predictions_count", predictions_count)
        if avg_confidence:
            mlflow.log_metric("avg_confidence", avg_confidence)
