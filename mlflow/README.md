# MLflow Integration - MindPulse Project ğŸš€

Guide complet pour l'intÃ©gration MLflow dans le projet de prÃ©diction de dÃ©pression Ã©tudiante.

## ğŸ“‹ Vue d'ensemble

MLflow est intÃ©grÃ© pour:
- **Tracking des expÃ©riences** - Suivi des mÃ©triques, paramÃ¨tres et artifacts
- **Model Registry** - Gestion des versions de modÃ¨les (Staging/Production)
- **Model Serving** - DÃ©ploiement simplifiÃ© des modÃ¨les
- **Comparaison des modÃ¨les** - Interface visuelle pour comparer les runs

## ğŸ—ï¸ Architecture

```
mlflow/
â”œâ”€â”€ docker-compose.yml       # Configuration Docker du serveur MLflow
â”œâ”€â”€ mlflow_config.py         # Module de configuration et utilitaires
â””â”€â”€ requirements.txt         # DÃ©pendances Python
```

## ğŸš€ DÃ©marrage rapide

### 1. Lancer le serveur MLflow

```bash
cd mlflow
docker compose up -d
```

Le serveur sera accessible sur: **http://localhost:5000**

### 2. EntraÃ®ner un modÃ¨le avec tracking

```bash
cd scripts
python train_with_mlflow.py
```

### 3. Visualiser les rÃ©sultats

Ouvrez http://localhost:5000 pour accÃ©der Ã  l'interface MLflow.

## ğŸ“Š FonctionnalitÃ©s

### Tracking des expÃ©riences

Chaque entraÃ®nement log automatiquement:

| Type | Description |
|------|-------------|
| **ParamÃ¨tres** | HyperparamÃ¨tres du modÃ¨le (n_estimators, max_depth, etc.) |
| **MÃ©triques** | accuracy, f1_score, precision, recall, roc_auc |
| **Artifacts** | ModÃ¨le sÃ©rialisÃ©, pipeline de preprocessing |
| **Tags** | Type de modÃ¨le, type d'entraÃ®nement, dataset |

### Model Registry

Les modÃ¨les sont automatiquement enregistrÃ©s avec les stages:

- **None** - ModÃ¨le juste enregistrÃ©
- **Staging** - ModÃ¨le en test
- **Production** - ModÃ¨le actif pour les prÃ©dictions
- **Archived** - Anciens modÃ¨les archivÃ©s

## ğŸ”§ Configuration

### Variables d'environnement

```bash
# URI du serveur MLflow
export MLFLOW_TRACKING_URI=http://localhost:5000

# Nom de l'expÃ©rience
export MLFLOW_EXPERIMENT_NAME=student-depression-prediction
```

### Configuration Docker

Le fichier `docker-compose.yml` configure:
- SQLite pour le backend store (production: PostgreSQL recommandÃ©)
- Volume persistant pour les artifacts
- Port 5000 exposÃ©

## ğŸ“ Structure des Runs

```
experiment/
â”œâ”€â”€ run_1/
â”‚   â”œâ”€â”€ metrics/
â”‚   â”‚   â”œâ”€â”€ accuracy
â”‚   â”‚   â”œâ”€â”€ f1_score
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ params/
â”‚   â”‚   â”œâ”€â”€ n_estimators
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ artifacts/
â”‚   â”‚   â””â”€â”€ model/
â”‚   â””â”€â”€ tags/
â””â”€â”€ run_2/
    â””â”€â”€ ...
```

## ğŸ”„ IntÃ©gration Airflow

Le DAG `ml_retrain_pipeline.py` intÃ¨gre MLflow pour:

1. **Tracking automatique** - Chaque rÃ©-entraÃ®nement crÃ©e un nouveau run
2. **Comparaison** - Compare avec le modÃ¨le en production
3. **Promotion automatique** - Passe en production si meilleur

### Variables Airflow requises

```python
MLFLOW_TRACKING_URI = "http://mlflow-server:5000"
```

## ğŸ“ Utilisation du module `mlflow_config.py`

### Setup initial

```python
from mlflow_config import setup_mlflow

experiment_id = setup_mlflow()
```

### Logger un entraÃ®nement

```python
from mlflow_config import log_model_training

run_id = log_model_training(
    model=trained_model,
    model_name="Random_Forest",
    metrics={"accuracy": 0.95, "f1_score": 0.94},
    params={"n_estimators": 100, "max_depth": 10},
    tags={"training_type": "initial"}
)
```

### Enregistrer le meilleur modÃ¨le

```python
from mlflow_config import compare_and_register_best_model

registered = compare_and_register_best_model(
    metrics={"accuracy": 0.95},
    model_name="Random_Forest",
    run_id=run_id
)
```

### Charger le modÃ¨le de production

```python
from mlflow_config import load_production_model

model = load_production_model()
predictions = model.predict(X_new)
```

## ğŸŒ API MLflow

### Endpoints utiles

| Endpoint | Description |
|----------|-------------|
| `GET /api/2.0/mlflow/experiments/list` | Liste des expÃ©riences |
| `GET /api/2.0/mlflow/runs/search` | Recherche de runs |
| `GET /api/2.0/mlflow/registered-models/list` | ModÃ¨les enregistrÃ©s |

### Exemple avec Python

```python
import mlflow
from mlflow.tracking import MlflowClient

client = MlflowClient("http://localhost:5000")

# Lister les expÃ©riences
experiments = client.search_experiments()

# Lister les runs d'une expÃ©rience
runs = client.search_runs(experiment_ids=["1"])

# Obtenir le modÃ¨le en production
versions = client.get_latest_versions("depression-classifier", stages=["Production"])
```

## ğŸ³ Docker Compose complet

Pour intÃ©grer MLflow avec les autres services:

```yaml
# Dans le docker-compose principal
services:
  mlflow-server:
    image: ghcr.io/mlflow/mlflow:v2.12.1
    ports:
      - "5000:5000"
    volumes:
      - mlflow_data:/mlflow
    command: mlflow server --host 0.0.0.0 --port 5000
    networks:
      - app-network

  webapp:
    # ... configuration existante
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow-server:5000
    depends_on:
      - mlflow-server
```

## ğŸ“ˆ Bonnes pratiques

1. **Nommage cohÃ©rent** - Utilisez des noms de runs descriptifs
2. **Tags informatifs** - Ajoutez des tags pour le filtrage
3. **Versioning des donnÃ©es** - Loggez la taille du dataset
4. **Comparaison systÃ©matique** - Comparez toujours avec la production
5. **Archivage** - Archivez les anciens modÃ¨les rÃ©guliÃ¨rement

## ğŸ” Troubleshooting

### Le serveur ne dÃ©marre pas

```bash
# VÃ©rifier les logs
docker compose logs mlflow-server

# RecrÃ©er le conteneur
docker compose down -v
docker compose up -d
```

### Connexion refusÃ©e

```bash
# VÃ©rifier que le serveur est accessible
curl http://localhost:5000/health
```

### Erreur de permission

```bash
# Donner les permissions sur le volume
chmod -R 777 ./mlflow_data
```

## ğŸ“š Ressources

- [Documentation MLflow](https://mlflow.org/docs/latest/index.html)
- [MLflow Model Registry](https://mlflow.org/docs/latest/model-registry.html)
- [MLflow Tracking](https://mlflow.org/docs/latest/tracking.html)
