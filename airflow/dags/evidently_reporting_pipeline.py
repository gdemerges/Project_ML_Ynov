"""
DAG Airflow pour la gÃ©nÃ©ration automatique de rapports Evidently
Projet: MindPulse - Student Depression Prediction
"""

from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.operators.bash import BashOperator
import pandas as pd
from pathlib import Path

# Configuration des chemins
DATA_PATH = Path("/opt/airflow/data")
REPORTS_PATH = Path("/opt/airflow/reports")


def check_data_availability(**context):
    """VÃ©rifie la disponibilitÃ© des donnÃ©es pour le reporting"""
    ref_data_path = DATA_PATH / "ref_data.csv"
    prod_data_path = DATA_PATH / "prod_data.csv"

    ref_exists = ref_data_path.exists()
    prod_exists = prod_data_path.exists()

    print(f"ğŸ“Š DonnÃ©es de rÃ©fÃ©rence: {'âœ… Disponibles' if ref_exists else 'âŒ Manquantes'}")
    print(f"ğŸ“Š DonnÃ©es de production: {'âœ… Disponibles' if prod_exists else 'âŒ Manquantes'}")

    if not ref_exists:
        raise FileNotFoundError("DonnÃ©es de rÃ©fÃ©rence manquantes")

    if not prod_exists:
        print("âš ï¸ Aucune donnÃ©e de production - gÃ©nÃ©ration de donnÃ©es vides")
        pd.DataFrame().to_csv(prod_data_path, index=False)

    return ref_exists and prod_exists


def generate_data_quality_report(**context):
    """GÃ©nÃ¨re un rapport de qualitÃ© des donnÃ©es avec Evidently"""
    from evidently.report import Report
    from evidently.metric_preset import DataQualityPreset

    ref_data_path = DATA_PATH / "ref_data.csv"
    prod_data_path = DATA_PATH / "prod_data.csv"

    ref_data = pd.read_csv(ref_data_path)

    # VÃ©rifier si prod_data est vide
    prod_data = pd.read_csv(prod_data_path)
    if len(prod_data) == 0:
        print("âš ï¸ Pas de donnÃ©es de production - utilisation des donnÃ©es de rÃ©fÃ©rence")
        prod_data = ref_data.sample(min(100, len(ref_data)))

    # CrÃ©er le rapport
    report = Report(metrics=[DataQualityPreset()])
    report.run(reference_data=ref_data, current_data=prod_data)

    # Sauvegarder le rapport
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_path = REPORTS_PATH / f"data_quality_report_{timestamp}.html"
    REPORTS_PATH.mkdir(exist_ok=True)
    report.save_html(str(report_path))

    print(f"âœ… Rapport de qualitÃ© gÃ©nÃ©rÃ©: {report_path}")


def generate_data_drift_report(**context):
    """GÃ©nÃ¨re un rapport de drift des donnÃ©es avec Evidently"""
    from evidently.report import Report
    from evidently.metric_preset import DataDriftPreset

    ref_data_path = DATA_PATH / "ref_data.csv"
    prod_data_path = DATA_PATH / "prod_data.csv"

    ref_data = pd.read_csv(ref_data_path)
    prod_data = pd.read_csv(prod_data_path)

    if len(prod_data) == 0:
        print("âš ï¸ Pas de donnÃ©es de production - saut du rapport de drift")
        return

    # CrÃ©er le rapport
    report = Report(metrics=[DataDriftPreset()])
    report.run(reference_data=ref_data, current_data=prod_data)

    # Sauvegarder le rapport
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_path = REPORTS_PATH / f"data_drift_report_{timestamp}.html"
    report.save_html(str(report_path))

    print(f"âœ… Rapport de drift gÃ©nÃ©rÃ©: {report_path}")


def generate_model_performance_report(**context):
    """GÃ©nÃ¨re un rapport de performance du modÃ¨le"""
    from evidently.report import Report
    from evidently.metric_preset import ClassificationPreset

    ref_data_path = DATA_PATH / "ref_data.csv"
    prod_data_path = DATA_PATH / "prod_data.csv"

    ref_data = pd.read_csv(ref_data_path)
    prod_data = pd.read_csv(prod_data_path)

    if len(prod_data) == 0 or 'target' not in prod_data.columns or 'prediction' not in prod_data.columns:
        print("âš ï¸ DonnÃ©es insuffisantes pour le rapport de performance")
        return

    # CrÃ©er le rapport
    report = Report(metrics=[ClassificationPreset()])
    report.run(
        reference_data=ref_data,
        current_data=prod_data,
        column_mapping={'target': 'target', 'prediction': 'prediction'}
    )

    # Sauvegarder le rapport
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_path = REPORTS_PATH / f"model_performance_report_{timestamp}.html"
    report.save_html(str(report_path))

    print(f"âœ… Rapport de performance gÃ©nÃ©rÃ©: {report_path}")


def cleanup_old_reports(**context):
    """Nettoie les anciens rapports (garde les 10 plus rÃ©cents)"""
    if not REPORTS_PATH.exists():
        return

    reports = sorted(REPORTS_PATH.glob("*.html"), key=lambda x: x.stat().st_mtime, reverse=True)

    if len(reports) > 10:
        for old_report in reports[10:]:
            old_report.unlink()
            print(f"ğŸ—‘ï¸ Rapport supprimÃ©: {old_report.name}")

    print(f"âœ… Nettoyage terminÃ© - {len(reports[:10])} rapports conservÃ©s")


def send_report_summary(**context):
    """Envoie un rÃ©sumÃ© des rapports gÃ©nÃ©rÃ©s"""
    ti = context['task_instance']

    print("\n" + "="*60)
    print("ğŸ“Š RAPPORTS EVIDENTLY GÃ‰NÃ‰RÃ‰S")
    print("="*60)
    print(f"ğŸ“… Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ“ RÃ©pertoire: {REPORTS_PATH}")
    print("="*60 + "\n")


# Configuration du DAG
default_args = {
    'owner': 'mindpulse',
    'depends_on_past': False,
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

with DAG(
    'evidently_reporting_pipeline',
    default_args=default_args,
    description='GÃ©nÃ©ration automatique de rapports Evidently pour le monitoring',
    schedule_interval='0 */6 * * *',  # Toutes les 6 heures
    start_date=datetime(2026, 2, 9),
    catchup=False,
    tags=['monitoring', 'evidently', 'mindpulse'],
) as dag:

    # Task 1: VÃ©rifier la disponibilitÃ© des donnÃ©es
    check_data = PythonOperator(
        task_id='check_data_availability',
        python_callable=check_data_availability,
    )

    # Task 2: GÃ©nÃ©rer le rapport de qualitÃ©
    quality_report = PythonOperator(
        task_id='generate_data_quality_report',
        python_callable=generate_data_quality_report,
    )

    # Task 3: GÃ©nÃ©rer le rapport de drift
    drift_report = PythonOperator(
        task_id='generate_data_drift_report',
        python_callable=generate_data_drift_report,
    )

    # Task 4: GÃ©nÃ©rer le rapport de performance
    performance_report = PythonOperator(
        task_id='generate_model_performance_report',
        python_callable=generate_model_performance_report,
    )

    # Task 5: Nettoyer les anciens rapports
    cleanup_reports = PythonOperator(
        task_id='cleanup_old_reports',
        python_callable=cleanup_old_reports,
    )

    # Task 6: Envoyer le rÃ©sumÃ©
    send_summary = PythonOperator(
        task_id='send_report_summary',
        python_callable=send_report_summary,
    )

    # DÃ©finir le workflow
    check_data >> [quality_report, drift_report, performance_report] >> cleanup_reports >> send_summary
