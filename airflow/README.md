# Airflow - Orchestration MLOps Pipeline

Ce dossier contient l'infrastructure Airflow pour l'orchestration automatique des pipelines MLOps du projet MindPulse.

## üìã Vue d'ensemble

Airflow est utilis√© pour automatiser :
- üîÑ **R√©entra√Ænement automatique** du mod√®le ML
- üìä **G√©n√©ration de rapports Evidently** (monitoring)
- üîç **D√©tection de drift** des donn√©es
- üìà **Suivi de performance** du mod√®le

## üèóÔ∏è Structure

```
airflow/
‚îú‚îÄ‚îÄ dags/                                # DAGs Airflow
‚îÇ   ‚îú‚îÄ‚îÄ ml_retrain_pipeline.py         # Pipeline de r√©entra√Ænement
‚îÇ   ‚îî‚îÄ‚îÄ evidently_reporting_pipeline.py # Pipeline de reporting
‚îú‚îÄ‚îÄ logs/                                # Logs d'ex√©cution
‚îú‚îÄ‚îÄ plugins/                             # Plugins personnalis√©s
‚îú‚îÄ‚îÄ config/                              # Configuration Airflow
‚îú‚îÄ‚îÄ docker-compose.yml                   # Orchestration Docker
‚îú‚îÄ‚îÄ requirements.txt                     # D√©pendances Python
‚îî‚îÄ‚îÄ README.md                           # Ce fichier
```

## üöÄ D√©marrage rapide

### 1. D√©finir l'UID utilisateur (Linux/macOS)

```bash
echo "AIRFLOW_UID=$(id -u)" > .env
```

### 2. Initialiser Airflow

```bash
docker compose up airflow-init
```

### 3. D√©marrer les services Airflow

```bash
docker compose up -d
```

### 4. Acc√©der √† l'interface web

Ouvrez votre navigateur √† : **http://localhost:8083**

**Identifiants par d√©faut :**
- Username: `admin`
- Password: `admin`

## üìä DAGs disponibles

### 1. `ml_retrain_pipeline` - R√©entra√Ænement automatique

**D√©clenchement :** Quotidien (schedule: `@daily`)

**Workflow :**
1. ‚úÖ V√©rifier les donn√©es de production (seuil: 1000 lignes)
2. üîç D√©tecter le drift des donn√©es
3. üíæ Sauvegarder le mod√®le actuel
4. üîó Fusionner ref_data + prod_data
5. ü§ñ Entra√Æner le nouveau mod√®le (comparaison: LR, RF, XGBoost)
6. üì¶ Archiver les donn√©es de production
7. üìß Notifier le succ√®s

**Conditions de r√©entra√Ænement :**
- Nombre de lignes dans `prod_data.csv` ‚â• 1000
- OU drift d√©tect√© (> 30% de colonnes avec drift)

**Activation manuelle :**
```bash
# Via l'interface web Airflow ou via CLI :
docker exec -it airflow-webserver airflow dags trigger ml_retrain_pipeline
```

### 2. `evidently_reporting_pipeline` - G√©n√©ration de rapports

**D√©clenchement :** Toutes les 6 heures (schedule: `0 */6 * * *`)

**Workflow :**
1. ‚úÖ V√©rifier la disponibilit√© des donn√©es
2. üìä G√©n√©rer rapport de qualit√© des donn√©es
3. üìâ G√©n√©rer rapport de drift
4. üìà G√©n√©rer rapport de performance du mod√®le
5. üóëÔ∏è Nettoyer les anciens rapports (garde les 10 plus r√©cents)
6. üìß Envoyer le r√©sum√©

**Rapports g√©n√©r√©s :**
- `data_quality_report_YYYYMMDD_HHMMSS.html`
- `data_drift_report_YYYYMMDD_HHMMSS.html`
- `model_performance_report_YYYYMMDD_HHMMSS.html`

**Emplacement :** `/opt/airflow/reports` (dans le conteneur)

## üîß Configuration

### Modifier les seuils de r√©entra√Ænement

√âditez `dags/ml_retrain_pipeline.py` :

```python
# Seuil pour d√©clencher le r√©entra√Ænement
RETRAIN_THRESHOLD = 1000  # Modifier cette valeur
```

### Modifier la fr√©quence d'ex√©cution

√âditez le param√®tre `schedule_interval` dans les DAGs :

```python
# Ex√©cution quotidienne
schedule_interval='@daily'

# Ex√©cution toutes les heures
schedule_interval='@hourly'

# Ex√©cution personnalis√©e (cron)
schedule_interval='0 */6 * * *'  # Toutes les 6 heures
```

## üìù Commandes utiles

### Voir les logs en temps r√©el

```bash
# Logs du webserver
docker logs -f airflow-webserver

# Logs du scheduler
docker logs -f airflow-scheduler
```

### Arr√™ter Airflow

```bash
docker compose down
```

### Red√©marrer Airflow

```bash
docker compose down && docker compose up -d
```

### Reconstruire les images

```bash
docker compose down
docker compose up --build -d
```

### Lister les DAGs

```bash
docker exec -it airflow-webserver airflow dags list
```

### Tester un DAG manuellement

```bash
# D√©clencher le r√©entra√Ænement
docker exec -it airflow-webserver airflow dags trigger ml_retrain_pipeline

# D√©clencher le reporting
docker exec -it airflow-webserver airflow dags trigger evidently_reporting_pipeline
```

### Activer/D√©sactiver un DAG

```bash
# Activer
docker exec -it airflow-webserver airflow dags unpause ml_retrain_pipeline

# D√©sactiver
docker exec -it airflow-webserver airflow dags pause ml_retrain_pipeline
```

## üêõ Debugging

### V√©rifier le statut des services

```bash
docker compose ps
```

### Acc√©der au shell du conteneur

```bash
docker exec -it airflow-webserver bash
```

### V√©rifier les erreurs dans les logs

```bash
# Logs du scheduler (o√π les DAGs s'ex√©cutent)
docker logs airflow-scheduler | grep ERROR

# Logs du webserver
docker logs airflow-webserver | grep ERROR
```

### Tester une t√¢che sp√©cifique

```bash
docker exec -it airflow-webserver airflow tasks test ml_retrain_pipeline check_production_data 2026-02-09
```

## üìö Ressources

- [Documentation Airflow](https://airflow.apache.org/docs/)
- [Documentation Evidently](https://docs.evidentlyai.com/)
- [DAG Writing Best Practices](https://airflow.apache.org/docs/apache-airflow/stable/best-practices.html)

## ‚öôÔ∏è Variables d'environnement

Variables configurables dans `docker-compose.yml` :

- `AIRFLOW__CORE__EXECUTOR`: Type d'executor (LocalExecutor par d√©faut)
- `AIRFLOW__DATABASE__SQL_ALCHEMY_CONN`: Connexion √† la base de donn√©es
- `AIRFLOW__WEBSERVER__SECRET_KEY`: Cl√© secr√®te pour le webserver

## üîí S√©curit√©

**‚ö†Ô∏è Important :** Les identifiants par d√©faut (`admin`/`admin`) doivent √™tre chang√©s en production !

Pour changer le mot de passe :

```bash
docker exec -it airflow-webserver airflow users create \
  --username YOUR_USERNAME \
  --firstname YOUR_FIRSTNAME \
  --lastname YOUR_LASTNAME \
  --role Admin \
  --email YOUR_EMAIL \
  --password YOUR_PASSWORD
```

## üìû Support

En cas de probl√®me :
1. Consultez les logs : `docker logs airflow-scheduler`
2. V√©rifiez l'interface web Airflow : http://localhost:8083
3. Consultez la documentation du projet

---

**MindPulse Analytics** ‚Ä¢ M1 DataEng ‚Ä¢ Ynov Campus ‚Ä¢ 2025-2026
