# ğŸ‰ ImplÃ©mentation Airflow - RÃ©sumÃ©

**Date :** 9 FÃ©vrier 2026
**Projet :** MindPulse Analytics - Student Depression Prediction
**Technologies :** Apache Airflow 2.9.0, Docker, PostgreSQL, Evidently AI

---

## âœ… Ce qui a Ã©tÃ© implÃ©mentÃ©

### 1. Infrastructure Airflow complÃ¨te

```
airflow/
â”œâ”€â”€ dags/
â”‚   â”œâ”€â”€ ml_retrain_pipeline.py              âœ… DAG de rÃ©entraÃ®nement automatique
â”‚   â””â”€â”€ evidently_reporting_pipeline.py     âœ… DAG de gÃ©nÃ©ration de rapports
â”œâ”€â”€ logs/                                    âœ… Logs des exÃ©cutions
â”œâ”€â”€ plugins/                                 âœ… Plugins personnalisÃ©s (vide pour l'instant)
â”œâ”€â”€ config/                                  âœ… Configuration Airflow
â”œâ”€â”€ docker-compose.yml                       âœ… Orchestration Docker complÃ¨te
â”œâ”€â”€ requirements.txt                         âœ… DÃ©pendances Python
â”œâ”€â”€ start.sh                                 âœ… Script de dÃ©marrage rapide
â”œâ”€â”€ .env                                     âœ… Variables d'environnement
â””â”€â”€ README.md                               âœ… Documentation complÃ¨te
```

### 2. DAG #1 : ml_retrain_pipeline (RÃ©entraÃ®nement automatique)

**Objectif :** RÃ©entraÃ®ner automatiquement le modÃ¨le ML lorsque certaines conditions sont remplies

**Schedule :** Quotidien (`@daily`)

**Workflow (7 tÃ¢ches) :**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. check_production_data                  â”‚  â† VÃ©rifie si â‰¥1000 lignes dans prod_data.csv
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. detect_drift                           â”‚  â† DÃ©tecte drift avec Evidently (>30%)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. backup_current_model                   â”‚  â† Sauvegarde model.pickle actuel
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. merge_production_data                  â”‚  â† Fusionne ref_data + prod_data
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. train_new_model                        â”‚  â† EntraÃ®ne LR, RF, XGBoost â†’ garde le meilleur
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. archive_production_data                â”‚  â† Archive prod_data â†’ nouveau fichier vide
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  7. notify_retrain_success                 â”‚  â† Notification + logs de mÃ©triques
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Triggers de rÃ©entraÃ®nement :**
- âœ… Seuil de donnÃ©es : `prod_data.csv` â‰¥ 1000 lignes
- âœ… Drift dÃ©tectÃ© : > 30% des features ont driftÃ©
- âœ… DÃ©clenchement manuel : Via interface Airflow

**Outputs :**
- `artifacts/model.pickle` (nouveau modÃ¨le)
- `artifacts/preprocessing_pipeline.pickle` (nouveau pipeline)
- `artifacts/model_backup_YYYYMMDD_HHMMSS.pickle` (backup)
- `data/prod_data_archived_YYYYMMDD_HHMMSS.csv` (archive)

---

### 3. DAG #2 : evidently_reporting_pipeline (Monitoring)

**Objectif :** GÃ©nÃ©rer automatiquement des rapports de monitoring avec Evidently AI

**Schedule :** Toutes les 6 heures (`0 */6 * * *`)

**Workflow (6 tÃ¢ches) :**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. check_data_availability                â”‚  â† VÃ©rifie ref_data.csv et prod_data.csv
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
         â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼           â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Quality   â”‚ â”‚ 3. Drift     â”‚ â”‚ 4. Perf      â”‚  â† GÃ©nÃ©ration parallÃ¨le des 3 rapports
â”‚    Report    â”‚ â”‚    Report    â”‚ â”‚    Report    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  5. cleanup_old_reports        â”‚  â† Garde uniquement les 10 plus rÃ©cents
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  6. send_report_summary        â”‚  â† Notification de succÃ¨s
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Rapports gÃ©nÃ©rÃ©s :**
- `reports/data_quality_report_YYYYMMDD_HHMMSS.html`
- `reports/data_drift_report_YYYYMMDD_HHMMSS.html`
- `reports/model_performance_report_YYYYMMDD_HHMMSS.html`

**MÃ©triques incluses :**
- ğŸ“Š Data Quality: valeurs manquantes, outliers, types de donnÃ©es
- ğŸ“‰ Data Drift: distribution des features, dÃ©tection de drift
- ğŸ“ˆ Model Performance: accuracy, F1-score, precision, recall

---

## ğŸ³ Docker Compose - Services

```yaml
services:
  âœ… postgres           # Base de donnÃ©es Airflow (port 5432)
  âœ… airflow-webserver  # Interface Web (port 8083)
  âœ… airflow-scheduler  # Ordonnanceur des DAGs
  âœ… airflow-init       # Initialisation (crÃ©ation admin user)
```

**RÃ©seau :** `airflow_network` (bridge)
**Volumes partagÃ©s :**
- `./dags` â†’ `/opt/airflow/dags`
- `./logs` â†’ `/opt/airflow/logs`
- `./plugins` â†’ `/opt/airflow/plugins`
- `../data` â†’ `/opt/airflow/data`
- `../artifacts` â†’ `/opt/airflow/artifacts`
- `../scripts` â†’ `/opt/airflow/scripts`

---

## ğŸš€ Comment dÃ©marrer ?

### Option 1 : Script automatique (RecommandÃ©)

```bash
cd airflow
./start.sh
```

### Option 2 : Manuelle

```bash
cd airflow

# 1. CrÃ©er .env (Linux/macOS)
echo "AIRFLOW_UID=$(id -u)" > .env

# 2. Initialiser Airflow
docker compose up airflow-init

# 3. DÃ©marrer les services
docker compose up -d

# 4. AccÃ©der Ã  l'interface
open http://localhost:8083
# Username: admin, Password: admin
```

---

## ğŸ“Š Interface Airflow - AperÃ§u

Une fois connectÃ© Ã  http://localhost:8083, vous verrez :

**Page d'accueil :**
```
DAG Name                          | Schedule      | Last Run | State
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€
ml_retrain_pipeline               | @daily        | Running  | ğŸŸ¢
evidently_reporting_pipeline      | 0 */6 * * *   | Success  | ğŸŸ¢
```

**Pour dÃ©clencher manuellement un DAG :**
1. Cliquer sur le DAG
2. Cliquer sur le bouton "â–¶ï¸ Trigger DAG" en haut Ã  droite
3. Confirmer

**Pour voir les logs d'une tÃ¢che :**
1. Cliquer sur le DAG
2. Cliquer sur "Graph View"
3. Cliquer sur une tÃ¢che
4. Cliquer sur "Log"

---

## ğŸ“ Nouveaux fichiers crÃ©Ã©s

```
âœ… airflow/docker-compose.yml                 # Orchestration complÃ¨te
âœ… airflow/requirements.txt                   # DÃ©pendances Python
âœ… airflow/start.sh                          # Script de dÃ©marrage
âœ… airflow/.env                              # Variables d'environnement
âœ… airflow/README.md                         # Documentation dÃ©taillÃ©e
âœ… airflow/dags/ml_retrain_pipeline.py       # DAG rÃ©entraÃ®nement (414 lignes)
âœ… airflow/dags/evidently_reporting_pipeline.py # DAG reporting (229 lignes)
âœ… reports/.gitkeep                          # Dossier pour rapports Evidently
âœ… MLOPS_GUIDE.md                            # Guide MLOps complet
âœ… AIRFLOW_IMPLEMENTATION_SUMMARY.md         # Ce fichier
```

**Fichiers modifiÃ©s :**
```
âœ… README.md                                 # Ajout section Airflow
âœ… webapp/app.py                             # Adaptation aux vraies features du modÃ¨le
```

---

## ğŸ¯ Prochaines Ã©tapes recommandÃ©es

### 1. Tester le systÃ¨me complet

```bash
# 1. DÃ©marrer tous les services
cd serving && docker compose up -d
cd ../webapp && docker compose up -d
cd ../airflow && ./start.sh

# 2. Faire des prÃ©dictions sur la webapp
open http://localhost:8081

# 3. Fournir des feedbacks (pour accumuler des donnÃ©es de production)

# 4. DÃ©clencher manuellement le rÃ©entraÃ®nement
open http://localhost:8083
# Trigger: ml_retrain_pipeline

# 5. Consulter les rapports gÃ©nÃ©rÃ©s
ls -lh reports/
```

### 2. Configurer pour votre environnement

**Ajuster les seuils de rÃ©entraÃ®nement :**

Ã‰diter `airflow/dags/ml_retrain_pipeline.py` :
```python
RETRAIN_THRESHOLD = 100  # Abaisser pour tester plus rapidement
```

**Modifier les schedules :**

```python
# RÃ©entraÃ®nement toutes les heures (pour tester)
schedule_interval='@hourly'

# Reporting toutes les 2 heures
schedule_interval='0 */2 * * *'
```

### 3. Monitoring en production

**Activer les notifications email :**

Dans `docker-compose.yml`, ajouter :
```yaml
AIRFLOW__EMAIL__EMAIL_BACKEND: 'airflow.utils.email.send_email_smtp'
AIRFLOW__SMTP__SMTP_HOST: 'smtp.gmail.com'
AIRFLOW__SMTP__SMTP_PORT: 587
AIRFLOW__SMTP__SMTP_USER: 'your-email@gmail.com'
AIRFLOW__SMTP__SMTP_PASSWORD: 'your-password'
```

Dans les DAGs, activer :
```python
default_args = {
    'email_on_failure': True,
    'email_on_retry': True,
    'email': ['your-email@example.com'],
}
```

---

## ğŸ”§ Commandes utiles

```bash
# Voir les logs en temps rÃ©el
docker logs -f airflow-scheduler
docker logs -f airflow-webserver

# ArrÃªter Airflow
cd airflow && docker compose down

# RedÃ©marrer Airflow
cd airflow && docker compose restart

# Voir le statut des services
docker compose ps

# Lister les DAGs depuis le CLI
docker exec -it airflow-webserver airflow dags list

# Tester un DAG
docker exec -it airflow-webserver airflow dags test ml_retrain_pipeline 2026-02-09

# Activer/DÃ©sactiver un DAG
docker exec -it airflow-webserver airflow dags unpause ml_retrain_pipeline
docker exec -it airflow-webserver airflow dags pause ml_retrain_pipeline

# AccÃ©der au shell du conteneur
docker exec -it airflow-webserver bash
```

---

## ğŸ“š Documentation

- **Airflow gÃ©nÃ©ral :** `airflow/README.md`
- **Architecture MLOps :** `MLOPS_GUIDE.md`
- **Application Streamlit :** `webapp/README.md`, `WEBAPP_GUIDE.md`
- **Projet gÃ©nÃ©ral :** `README.md`

---

## âœ¨ FonctionnalitÃ©s clÃ©s

### âœ… RÃ©entraÃ®nement intelligent
- DÃ©clenchÃ© automatiquement quand nÃ©cessaire
- Comparaison de 3 algorithmes (LR, RF, XGBoost)
- SÃ©lection automatique du meilleur modÃ¨le
- Backup automatique avant rÃ©entraÃ®nement
- Rollback possible en cas de problÃ¨me

### âœ… Monitoring continu
- Rapports de qualitÃ© des donnÃ©es
- DÃ©tection de drift automatique
- Suivi de performance du modÃ¨le
- Visualisations HTML interactives
- Historique des 10 derniers rapports

### âœ… Production-ready
- Conteneurisation complÃ¨te (Docker)
- Orchestration avec Docker Compose
- Base de donnÃ©es PostgreSQL pour Airflow
- Logs persistants
- Gestion des erreurs et retry
- Interface web intuitive

---

## ğŸ“ Concepts MLOps implÃ©mentÃ©s

âœ… **Continuous Training (CT)** - RÃ©entraÃ®nement automatique basÃ© sur triggers
âœ… **Model Versioning** - Backup automatique des modÃ¨les
âœ… **Data Drift Detection** - Surveillance de la qualitÃ© des donnÃ©es
âœ… **Model Monitoring** - Suivi des performances en production
âœ… **Automated Pipelines** - Orchestration avec Airflow
âœ… **Feedback Loop** - Collecte des vraies labels pour amÃ©lioration
âœ… **Containerization** - DÃ©ploiement avec Docker

---

## ğŸ† RÃ©sultat final

Vous disposez maintenant d'une **plateforme MLOps complÃ¨te** pour :

1. âœ… **Servir** des prÃ©dictions (FastAPI)
2. âœ… **PrÃ©senter** une interface utilisateur (Streamlit)
3. âœ… **Collecter** des feedbacks (API /feedback)
4. âœ… **Surveiller** les performances (Evidently)
5. âœ… **RÃ©entraÃ®ner** automatiquement (Airflow)
6. âœ… **DÃ©ployer** de nouveaux modÃ¨les (Automated)

Le systÃ¨me est **autonome** et **scalable**, prÃªt pour la production ! ğŸš€

---

**MindPulse Analytics** â€¢ MLOps Platform â€¢ M1 DataEng â€¢ Ynov 2025-2026
