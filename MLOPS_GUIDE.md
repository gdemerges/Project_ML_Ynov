# Guide MLOps - MindPulse Analytics

Ce guide d√©crit l'architecture MLOps compl√®te du projet et le flux de donn√©es automatis√©.

## üìä Vue d'ensemble de l'architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         UTILISATEUR                                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                            ‚ñº
                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                  ‚îÇ  Streamlit WebApp   ‚îÇ  Port 8081
                  ‚îÇ  (Interface User)   ‚îÇ
                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ HTTP POST /predict
                            ‚ñº
                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                  ‚îÇ   FastAPI Serving   ‚îÇ  Port 8080
                  ‚îÇ  (Mod√®le ML + API)  ‚îÇ
                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ             ‚îÇ             ‚îÇ
              ‚ñº             ‚ñº             ‚ñº
      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
      ‚îÇ Pr√©dire  ‚îÇ   ‚îÇ Feedback ‚îÇ   ‚îÇ  Stocker ‚îÇ
      ‚îÇ  avec    ‚îÇ   ‚îÇ   Loop   ‚îÇ   ‚îÇ  dans    ‚îÇ
      ‚îÇ  Mod√®le  ‚îÇ   ‚îÇ          ‚îÇ   ‚îÇprod_data ‚îÇ
      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                          ‚îÇ
                                          ‚ñº
                            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                            ‚îÇ   Apache Airflow         ‚îÇ  Port 8083
                            ‚îÇ  (Orchestration MLOps)   ‚îÇ
                            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                      ‚îÇ
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ                     ‚îÇ                     ‚îÇ
                ‚ñº                     ‚ñº                     ‚ñº
      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
      ‚îÇ DAG: Retrain     ‚îÇ  ‚îÇ DAG: Reporting   ‚îÇ  ‚îÇ DAG: Monitoring  ‚îÇ
      ‚îÇ (Quotidien)      ‚îÇ  ‚îÇ (Toutes les 6h)  ‚îÇ  ‚îÇ (Continu)        ‚îÇ
      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ                     ‚îÇ                     ‚îÇ
               ‚ñº                     ‚ñº                     ‚ñº
      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
      ‚îÇ Nouveau Mod√®le   ‚îÇ  ‚îÇ Rapports HTML    ‚îÇ  ‚îÇ Alertes + Logs   ‚îÇ
      ‚îÇ dans artifacts/  ‚îÇ  ‚îÇ dans reports/    ‚îÇ  ‚îÇ                  ‚îÇ
      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üîÑ Flux de donn√©es d√©taill√©

### 1. Phase de pr√©diction (Runtime)

```
1. Utilisateur remplit le formulaire Streamlit
   ‚Üì
2. Webapp envoie POST √† /predict avec les features
   ‚Üì
3. FastAPI charge le mod√®le (artifacts/model.pickle)
   ‚Üì
4. Preprocessing avec pipeline (artifacts/preprocessing_pipeline.pickle)
   ‚Üì
5. Pr√©diction ML (0: Pas de d√©pression, 1: D√©pression)
   ‚Üì
6. R√©ponse JSON retourn√©e √† Streamlit
   ‚Üì
7. Affichage du r√©sultat √† l'utilisateur
```

### 2. Phase de feedback (Continuous Learning)

```
1. Utilisateur fournit le vrai r√©sultat (actual)
   ‚Üì
2. Webapp envoie POST √† /feedback
   ‚Üì
3. FastAPI sauvegarde dans data/prod_data.csv
   ‚Üì
4. Ajout de: features + prediction + actual + timestamp
   ‚Üì
5. Donn√©es accumul√©es pour r√©entra√Ænement futur
```

### 3. Phase de monitoring (Toutes les 6 heures)

```
Airflow DAG: evidently_reporting_pipeline
‚Üì
1. Lire ref_data.csv (donn√©es d'entra√Ænement)
   ‚Üì
2. Lire prod_data.csv (donn√©es de production)
   ‚Üì
3. Comparer avec Evidently AI
   ‚îú‚îÄ‚îÄ Data Quality Report (valeurs manquantes, outliers)
   ‚îú‚îÄ‚îÄ Data Drift Report (distribution des features)
   ‚îî‚îÄ‚îÄ Model Performance Report (accuracy, F1, pr√©cision)
   ‚Üì
4. G√©n√©rer rapports HTML dans reports/
   ‚Üì
5. Nettoyer les anciens rapports (garde les 10 plus r√©cents)
```

### 4. Phase de r√©entra√Ænement (Quotidien)

```
Airflow DAG: ml_retrain_pipeline
‚Üì
1. CHECK: prod_data.csv >= 1000 lignes ?
   ‚îú‚îÄ‚îÄ OUI ‚Üí Continue
   ‚îî‚îÄ‚îÄ NON ‚Üí Skip (pas assez de donn√©es)
   ‚Üì
2. CHECK: Drift d√©tect√© avec Evidently ?
   ‚îú‚îÄ‚îÄ OUI ‚Üí Continue (drift > 30%)
   ‚îî‚îÄ‚îÄ NON ‚Üí Continue quand m√™me si step 1 = OUI
   ‚Üì
3. BACKUP: Sauvegarder mod√®le actuel
   - artifacts/model_backup_YYYYMMDD_HHMMSS.pickle
   - artifacts/preprocessing_pipeline_backup_YYYYMMDD_HHMMSS.pickle
   ‚Üì
4. MERGE: Fusionner ref_data + prod_data
   - Cr√©er merged_training_data.csv
   - Supprimer les doublons
   ‚Üì
5. TRAIN: Entra√Æner 3 mod√®les
   - Logistic Regression
   - Random Forest
   - XGBoost
   ‚Üì
6. SELECT: Garder le meilleur (accuracy)
   ‚Üì
7. SAVE: Remplacer model.pickle
   ‚Üì
8. ARCHIVE: D√©placer prod_data.csv
   - prod_data_archived_YYYYMMDD_HHMMSS.csv
   - Cr√©er nouveau prod_data.csv vide
   ‚Üì
9. NOTIFY: Logger le succ√®s avec m√©triques
```

## üéØ Triggers de r√©entra√Ænement

Le r√©entra√Ænement est d√©clench√© automatiquement si **AU MOINS UNE** des conditions suivantes est remplie :

1. **Seuil de donn√©es** : `prod_data.csv` contient ‚â• 1000 lignes
2. **Drift d√©tect√©** : Plus de 30% des features ont drift√©
3. **Performance d√©grad√©e** : Accuracy < seuil d√©fini (configurable)
4. **D√©clenchement manuel** : Via l'interface Airflow

## üìÅ Structure des fichiers de donn√©es

```
data/
‚îú‚îÄ‚îÄ student_lifestyle_100k.csv          # Dataset original Kaggle
‚îú‚îÄ‚îÄ ref_data.csv                        # Donn√©es d'entra√Ænement (PCA)
‚îú‚îÄ‚îÄ prod_data.csv                       # Donn√©es de production (accumul√©es)
‚îú‚îÄ‚îÄ merged_training_data.csv            # Fusion ref + prod (temporaire)
‚îî‚îÄ‚îÄ prod_data_archived_YYYYMMDD.csv    # Archives des r√©entra√Ænements

artifacts/
‚îú‚îÄ‚îÄ model.pickle                        # Mod√®le actuel en production
‚îú‚îÄ‚îÄ preprocessing_pipeline.pickle       # Pipeline de preprocessing
‚îú‚îÄ‚îÄ model_backup_YYYYMMDD.pickle       # Backups des mod√®les
‚îî‚îÄ‚îÄ preprocessing_pipeline_backup_*.pkl # Backups des pipelines

reports/
‚îú‚îÄ‚îÄ data_quality_report_*.html          # Rapports de qualit√©
‚îú‚îÄ‚îÄ data_drift_report_*.html            # Rapports de drift
‚îî‚îÄ‚îÄ model_performance_report_*.html     # Rapports de performance
```

## üîß Configuration des DAGs Airflow

### ml_retrain_pipeline.py

**Param√®tres configurables :**

```python
# Seuil minimum de donn√©es pour d√©clencher le r√©entra√Ænement
RETRAIN_THRESHOLD = 1000  # lignes dans prod_data.csv

# Seuil de drift acceptable
DRIFT_THRESHOLD = 0.3  # 30% max de colonnes avec drift

# Schedule
schedule_interval='@daily'  # Ex√©cution quotidienne √† minuit
```

**Modifier le schedule :**
```python
schedule_interval='@hourly'           # Toutes les heures
schedule_interval='0 */6 * * *'       # Toutes les 6 heures
schedule_interval='0 2 * * *'         # Tous les jours √† 2h du matin
schedule_interval='0 0 * * 0'         # Tous les dimanches √† minuit
```

### evidently_reporting_pipeline.py

**Param√®tres configurables :**

```python
# Nombre de rapports √† conserver
MAX_REPORTS = 10  # Garde les 10 plus r√©cents

# Schedule
schedule_interval='0 */6 * * *'  # Toutes les 6 heures
```

## üöÄ Guide de d√©ploiement complet

### 1. D√©marrage initial

```bash
# 1. Entra√Æner le mod√®le initial
cd scripts
jupyter notebook students.ipynb
# Ex√©cuter toutes les cellules ‚Üí g√©n√®re artifacts/ et data/ref_data.csv

# 2. D√©marrer l'API de serving
cd ../serving
docker compose up -d

# 3. D√©marrer la webapp Streamlit
cd ../webapp
docker compose up -d

# 4. D√©marrer Airflow
cd ../airflow
./start.sh
```

### 2. V√©rification du syst√®me

```bash
# V√©rifier que tous les services sont up
docker ps

# Devrait montrer :
# - serving-api (port 8080)
# - webapp (port 8081)
# - airflow-webserver (port 8083)
# - airflow-scheduler
# - postgres (Airflow DB)
```

### 3. Test du flux complet

```bash
# 1. Aller sur la webapp
open http://localhost:8081

# 2. Faire une pr√©diction
# Remplir le formulaire ‚Üí Cliquer "Run Analysis"

# 3. Fournir un feedback
# Indiquer le vrai r√©sultat ‚Üí Cliquer "Submit feedback"

# 4. V√©rifier que les donn√©es sont sauvegard√©es
cat data/prod_data.csv

# 5. Aller sur Airflow
open http://localhost:8083
# Username: admin, Password: admin

# 6. Activer les DAGs
# Cliquer sur les toggles pour activer les 2 DAGs

# 7. D√©clencher manuellement le r√©entra√Ænement
# Dans Airflow UI ‚Üí ml_retrain_pipeline ‚Üí Trigger DAG
```

## üìä Monitoring et observabilit√©

### Logs Airflow

```bash
# Logs du scheduler (ex√©cution des DAGs)
docker logs -f airflow-scheduler

# Logs du webserver
docker logs -f airflow-webserver

# Logs d'un DAG sp√©cifique
# Via l'interface Airflow ‚Üí DAG ‚Üí Graph View ‚Üí Task ‚Üí Log
```

### M√©triques √† surveiller

1. **Volume de donn√©es**
   - Nombre de lignes dans `prod_data.csv`
   - Taux de feedback (predictions avec actual)

2. **Performance du mod√®le**
   - Accuracy en production (via rapports Evidently)
   - F1-Score
   - Precision / Recall

3. **Drift des donn√©es**
   - % de features avec drift significatif
   - Distribution des features (histogrammes)

4. **Sant√© du pipeline**
   - Succ√®s/√âchec des DAG runs
   - Dur√©e d'ex√©cution des t√¢ches
   - Erreurs dans les logs

## üîê S√©curit√© et bonnes pratiques

### En production

1. **Changer les credentials Airflow**
```bash
docker exec -it airflow-webserver airflow users create \
  --username YOUR_USER \
  --password YOUR_SECURE_PASSWORD \
  --firstname YOUR_NAME \
  --lastname YOUR_LASTNAME \
  --role Admin \
  --email YOUR_EMAIL
```

2. **Configurer la persistance des volumes**
```yaml
# Dans docker-compose.yml
volumes:
  - ./data:/opt/airflow/data:rw
  - ./artifacts:/opt/airflow/artifacts:rw
  - ./reports:/opt/airflow/reports:rw
```

3. **Activer les notifications**
- Email en cas d'√©chec des DAGs
- Slack webhooks pour alertes
- Grafana pour monitoring temps r√©el

4. **Backup r√©gulier**
```bash
# Backup des mod√®les
cp -r artifacts/ backups/artifacts_$(date +%Y%m%d)/

# Backup de la BDD Airflow
docker exec postgres pg_dump -U airflow airflow > backup_airflow_$(date +%Y%m%d).sql
```

## üêõ Troubleshooting

### Probl√®me : DAG ne s'ex√©cute pas

**Solution :**
```bash
# 1. V√©rifier que le scheduler est actif
docker logs airflow-scheduler

# 2. V√©rifier les erreurs dans le DAG
docker exec -it airflow-scheduler airflow dags list-import-errors

# 3. Tester le DAG manuellement
docker exec -it airflow-scheduler airflow dags test ml_retrain_pipeline 2026-02-09
```

### Probl√®me : R√©entra√Ænement ne se d√©clenche pas

**Solution :**
```bash
# 1. V√©rifier le nombre de lignes dans prod_data.csv
wc -l data/prod_data.csv

# 2. Ajuster le seuil dans le DAG
# √âditer airflow/dags/ml_retrain_pipeline.py
RETRAIN_THRESHOLD = 10  # Abaisser le seuil pour tester

# 3. D√©clencher manuellement
# Via Airflow UI ‚Üí Trigger DAG
```

### Probl√®me : Mod√®le ne se charge pas apr√®s r√©entra√Ænement

**Solution :**
```bash
# 1. V√©rifier que le fichier existe
ls -lh artifacts/model.pickle

# 2. Restaurer le backup si n√©cessaire
cp artifacts/model_backup_YYYYMMDD_HHMMSS.pickle artifacts/model.pickle

# 3. Red√©marrer l'API
docker restart serving-api
```

## üìö Ressources

- [Documentation Airflow](https://airflow.apache.org/docs/)
- [Documentation Evidently AI](https://docs.evidentlyai.com/)
- [MLOps Best Practices](https://ml-ops.org/)
- [Continuous Training in ML](https://martinfowler.com/articles/cd4ml.html)

---

**MindPulse Analytics** ‚Ä¢ MLOps Pipeline ‚Ä¢ M1 DataEng ‚Ä¢ Ynov 2025-2026
